{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d58e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chapter04から使用するテキストデータをコピーする（事前にChapter04/Sentiment.ipynbを実行してください）\n",
    "!cp -r ../../Chapter04/sisyou_db ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import spacy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "## モデルのロード\n",
    "nlp = spacy.load(\"ja_ginza\")\n",
    "\n",
    "data_dir = \"sisyou_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec478cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 労災データベールからのファイルダウンロード\n",
    "## 労働災害データベースからのダウンロードを下記で行っていますが、\n",
    "## 本NotebookでははChapter04からコピーしているため、ダウンロード自体は行われません。\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "years = [28, 29]\n",
    "months = list(range(1, 13))\n",
    "\n",
    "## 労働災害データベースからのダウンロードを下記て行っていますが、\n",
    "## 本NotebookでははChapter04からコピーしているため、ダウンロード自体は行われません。\n",
    "\n",
    "for y in years:\n",
    "    for m in months:\n",
    "        file_url = f\"https://anzeninfo.mhlw.go.jp/anzen/shisyo_xls/sisyou_db_h{y}_{m:02d}.xlsx\"\n",
    "        file_name = f\"{data_dir}/sisyou_db_h{y}_{m:02d}.xlsx\"\n",
    "        if not os.path.exists(file_name):\n",
    "            res = requests.get(file_url)\n",
    "            print(file_name)\n",
    "            with open(file_name, 'wb') as f:\n",
    "                f.write(res.content)\n",
    "\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = list(range(1, 13))\n",
    "## 労災データの読み込み\n",
    "def read_rousai_db(data_dir, year_months):\n",
    "    dfs = []\n",
    "    for y, m in year_months:\n",
    "        file_name = \"{}/sisyou_db_h{}_{:02d}.xlsx\".format(data_dir, y, m)\n",
    "        df = pd.read_excel(file_name, skiprows=[1])\n",
    "        dfs.append(df)\n",
    "    df_ret = pd.concat(dfs)\n",
    "    df_ret = df_ret.rename(columns={\"事故の型\": \"事故の型_コード\",\n",
    "                                    \"Unnamed: 20\": \"事故の型_名前\"})\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba30073",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 訓練データ・テストデータの読み込み\n",
    "year_months_train = [(28, m) for m in months]\n",
    "year_months_test = [(29, 1)]\n",
    "df_train = read_rousai_db(data_dir, year_months_train)\n",
    "df_test = read_rousai_db(data_dir, year_months_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  読み込んだデータフレームのベクトル化\n",
    "def create_vector(df, nlp, name2label):\n",
    "    docs = nlp.pipe(df[\"災害状況\"],\n",
    "                    disable=['parser', 'ner', 'morphologizer',\n",
    "                             'compound_splitter', 'bunsetu_recognizer'])\n",
    "    vecs = [doc.vector for doc in docs]\n",
    "    X = np.array(vecs)\n",
    "    y = df[\"事故の型_名前\"].map(name2label).to_numpy()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49745bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df_train[\"事故の型_名前\"].unique()\n",
    "name2label = {name: i for i, name in enumerate(names)}\n",
    "\n",
    "%time X_train, y_train = create_vector(df_train, nlp, name2label)\n",
    "%time X_test, y_test = create_vector(df_test, nlp, name2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 文書分類モデルの学習と評価\n",
    "forest = RandomForestClassifier(n_jobs=-1)\n",
    "scores = cross_val_score(forest, X_train, y_train, cv=5)\n",
    "print(scores)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75faaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_category = df_train[\"事故の型_名前\"].value_counts()[0:10].index.to_list()\n",
    "name2label = {name: top10_category.index(name) if name in top10_category else len(top10_category) for i, name in enumerate(names)}\n",
    "print(top10_category)\n",
    "\n",
    "%time X_train, y_train = create_vector(df_train, nlp, name2label)\n",
    "%time X_test, y_test = create_vector(df_test, nlp, name2label)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'accuracy: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18018e41722abe2d0132f8df803b6bc8ce2c6c557cb152ba443126053cce7fe4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ginza4.0': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
