{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c1bcae-fcb8-4251-817f-8a39f3f8591d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ginzaの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f81dd-0f41-49c8-8423-624c7a7ef445",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 基本的な使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b883d5a-e7a0-48e7-8f44-8f5494bb2dca",
   "metadata": {
    "tags": []
   },
   "source": [
    "モデルを指定して解析器を読み込む．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ebcc6-5254-4629-85f6-6d23816f6192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ja_ginza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61521fb2-62fa-4ab9-a8b8-de87881ce221",
   "metadata": {},
   "source": [
    "その解析器を用いて，文章を単語に分割することができる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48800c40-f5ce-4aee-969e-c1bf75a78c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"昨日の天気は雨でした。晴れてほしかった。\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d504428-0049-4d6b-bb24-efc3ccd17d40",
   "metadata": {},
   "source": [
    "分割された単語には，出現形(text)，原形(lemma_)，品詞(tag_)が属性として付与される[<sup>1</sup>](#id1)．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9fd43c-6760-4360-be5a-28be0092db46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.tag_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab62f7-2949-403f-b20a-631850e8aa06",
   "metadata": {},
   "source": [
    "pandasのDataFrameに解析結果を格納する方法はこのようになる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0293a5-037a-4eeb-8d6d-1b5aca8de83f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text': token.text,\n",
    "    'lemma_': token.lemma_,\n",
    "    'pos_': token.pos_,\n",
    "    'tag_': token.tag_\n",
    "    } for token in doc)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11fccda-2ee0-4554-8d13-2f325ee2cb7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "さきほど用意した小説を単語に分割してみよう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843df918-e9e9-4f94-9ac7-365e88fd61d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_fn = 'text/kageotoko.corpus.txt'\n",
    "output_fn = 'text/kageotoko.wakati.txt'\n",
    "\n",
    "with open(input_fn, 'r') as fin, open(output_fn, 'w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = [token.text for token in nlp(line.rstrip())]\n",
    "        fout.write(' '.join(tokens)+'\\n')\n",
    "\n",
    "!head text/kageotoko.wakati.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a3607d-ae21-4b7b-91ed-e90573fd8adf",
   "metadata": {},
   "source": [
    "単語の出現頻度を数えてみよう．活用する語の活用形を別々に数えるのではなく，原形で集計する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eeb237-1006-4d63-80d4-b794fd2078ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "include_pos = ('NOUN', 'VERB', 'ADJ')\n",
    "stopwords = ('する', 'ある', 'ない', 'いう', 'もの', 'こと', 'よう', 'なる', 'ほう')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d311642-1f76-45ee-a083-650712b676f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_fn, 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "doc = nlp(text)\n",
    "counter = Counter(token.lemma_ for token in doc\n",
    "                  if token.pos_ in include_pos and token.lemma_ not in stopwords)\n",
    "\n",
    "print('count word')\n",
    "for word, count in counter.most_common(10):\n",
    "     print(f'{count:>5} {word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c43c40-5141-49d3-8af1-6766235a79db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 注釈\n",
    "<sup>1</sup> <span id=id1>pos_属性は，Universal Dependencyの品詞体系．</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
