{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c1bcae-fcb8-4251-817f-8a39f3f8591d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ginzaの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f81dd-0f41-49c8-8423-624c7a7ef445",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 基本的な使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b883d5a-e7a0-48e7-8f44-8f5494bb2dca",
   "metadata": {
    "tags": []
   },
   "source": [
    "モデルを指定して解析器を読み込む．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916ebcc6-5254-4629-85f6-6d23816f6192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ja_ginza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61521fb2-62fa-4ab9-a8b8-de87881ce221",
   "metadata": {},
   "source": [
    "その解析器を用いて，文章を単語に分割することができる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48800c40-f5ce-4aee-969e-c1bf75a78c33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "昨日\n",
      "の\n",
      "天気\n",
      "は\n",
      "雨\n",
      "でし\n",
      "た\n",
      "。\n",
      "晴れ\n",
      "て\n",
      "ほしかっ\n",
      "た\n",
      "。\n"
     ]
    }
   ],
   "source": [
    "text = \"昨日の天気は雨でした。晴れてほしかった。\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda1491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d504428-0049-4d6b-bb24-efc3ccd17d40",
   "metadata": {},
   "source": [
    "分割された単語には，出現形(text)，原形(lemma_)，品詞(tag_)が属性として付与される[<sup>1</sup>](#id1)．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9fd43c-6760-4360-be5a-28be0092db46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "昨日\t昨日\tNOUN\t名詞-普通名詞-副詞可能\n",
      "の\tの\tADP\t助詞-格助詞\n",
      "天気\t天気\tNOUN\t名詞-普通名詞-一般\n",
      "は\tは\tADP\t助詞-係助詞\n",
      "雨\t雨\tNOUN\t名詞-普通名詞-一般\n",
      "でし\tです\tAUX\t助動詞\n",
      "た\tた\tAUX\t助動詞\n",
      "。\t。\tPUNCT\t補助記号-句点\n",
      "晴れ\t晴れる\tVERB\t動詞-一般\n",
      "て\tて\tSCONJ\t助詞-接続助詞\n",
      "ほしかっ\tほしい\tADJ\t形容詞-非自立可能\n",
      "た\tた\tAUX\t助動詞\n",
      "。\t。\tPUNCT\t補助記号-句点\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.tag_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab62f7-2949-403f-b20a-631850e8aa06",
   "metadata": {},
   "source": [
    "pandasのDataFrameに解析結果を格納する方法はこのようになる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca0293a5-037a-4eeb-8d6d-1b5aca8de83f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>pos_</th>\n",
       "      <th>tag_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>昨日</td>\n",
       "      <td>昨日</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>名詞-普通名詞-副詞可能</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>の</td>\n",
       "      <td>の</td>\n",
       "      <td>ADP</td>\n",
       "      <td>助詞-格助詞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>天気</td>\n",
       "      <td>天気</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>名詞-普通名詞-一般</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>は</td>\n",
       "      <td>は</td>\n",
       "      <td>ADP</td>\n",
       "      <td>助詞-係助詞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>雨</td>\n",
       "      <td>雨</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>名詞-普通名詞-一般</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>でし</td>\n",
       "      <td>です</td>\n",
       "      <td>AUX</td>\n",
       "      <td>助動詞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>た</td>\n",
       "      <td>た</td>\n",
       "      <td>AUX</td>\n",
       "      <td>助動詞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>。</td>\n",
       "      <td>。</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>補助記号-句点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>晴れ</td>\n",
       "      <td>晴れる</td>\n",
       "      <td>VERB</td>\n",
       "      <td>動詞-一般</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>て</td>\n",
       "      <td>て</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>助詞-接続助詞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ほしかっ</td>\n",
       "      <td>ほしい</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>形容詞-非自立可能</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>た</td>\n",
       "      <td>た</td>\n",
       "      <td>AUX</td>\n",
       "      <td>助動詞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>。</td>\n",
       "      <td>。</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>補助記号-句点</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text lemma_   pos_          tag_\n",
       "0     昨日     昨日   NOUN  名詞-普通名詞-副詞可能\n",
       "1      の      の    ADP        助詞-格助詞\n",
       "2     天気     天気   NOUN    名詞-普通名詞-一般\n",
       "3      は      は    ADP        助詞-係助詞\n",
       "4      雨      雨   NOUN    名詞-普通名詞-一般\n",
       "5     でし     です    AUX           助動詞\n",
       "6      た      た    AUX           助動詞\n",
       "7      。      。  PUNCT       補助記号-句点\n",
       "8     晴れ    晴れる   VERB         動詞-一般\n",
       "9      て      て  SCONJ       助詞-接続助詞\n",
       "10  ほしかっ    ほしい    ADJ     形容詞-非自立可能\n",
       "11     た      た    AUX           助動詞\n",
       "12     。      。  PUNCT       補助記号-句点"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text': token.text,\n",
    "    'lemma_': token.lemma_,\n",
    "    'pos_': token.pos_,\n",
    "    'tag_': token.tag_\n",
    "    } for token in doc)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11fccda-2ee0-4554-8d13-2f325ee2cb7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "さきほど用意した小説を単語に分割してみよう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843df918-e9e9-4f94-9ac7-365e88fd61d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5812/1053355069.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mfout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "input_fn = 'text/kageotoko.corpus.txt'\n",
    "output_fn = 'text/kageotoko.wakati.txt'\n",
    "\n",
    "with open(input_fn, 'r',encoding=\"utf-8\") as fin, open(output_fn, 'w',encoding=\"utf-8\") as fout:\n",
    "    for line in fin:\n",
    "        tokens = [token.text for token in nlp(line.rstrip())]\n",
    "        fout.write(' '.join(tokens)+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a3607d-ae21-4b7b-91ed-e90573fd8adf",
   "metadata": {},
   "source": [
    "単語の出現頻度を数えてみよう．活用する語の活用形を別々に数えるのではなく，原形で集計する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53eeb237-1006-4d63-80d4-b794fd2078ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "include_pos = ('NOUN', 'VERB', 'ADJ')\n",
    "stopwords = ('する', 'ある', 'ない', 'いう', 'もの', 'こと', 'よう', 'なる', 'ほう')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d311642-1f76-45ee-a083-650712b676f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count word\n",
      "  224 お\n",
      "  212 中\n",
      "  206 人\n",
      "  199 男\n",
      "  176 顔\n",
      "  172 ふたり\n",
      "  137 つ\n",
      "  135 わかる\n",
      "  129 目\n",
      "  127 見える\n"
     ]
    }
   ],
   "source": [
    "with open(input_fn, 'r',encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "doc = nlp(text)\n",
    "counter = Counter(token.lemma_ for token in doc\n",
    "                  if token.pos_ in include_pos and token.lemma_ not in stopwords)\n",
    "\n",
    "print('count word')\n",
    "for word, count in counter.most_common(10):\n",
    "     print(f'{count:>5} {word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c609fb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 2), ('b', 1)]\n"
     ]
    }
   ],
   "source": [
    "cnt=Counter([\"a\",\"a\",\"b\",\"c\"])\n",
    "print(cnt.most_common(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c43c40-5141-49d3-8af1-6766235a79db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 注釈\n",
    "<sup>1</sup> <span id=id1>pos_属性は，Universal Dependencyの品詞体系．</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
